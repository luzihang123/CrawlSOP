# CrawlSOP
爬虫SOP（数据采集标准化工作流程)

## 为什么有这篇文章

爬虫开发干了好几年了，最近开始回过头整理通过实践获得的认知，并尝试将其梳理为一个方法论。

当然这个体系还不完善，但一直没有找到同一个方向又更为完善的。所以不如自己来整理和维护，对自己而言可以定期回顾修正，读过的大家也可以来参与补充。

## 什么是数据采集标准化工作流程

- 什么是SOP（标准化工作流程）

所谓SOP，是 Standard Operating Procedure三个单词中首字母的大写 ，即标准作业程序，指将某一事件的标准操作步骤和要求以统一的格式描述出来，用于指导和规范日常的工作。SOP的精髓是将细节进行量化，通俗来讲，SOP就是对某一程序中的关键控制点进行细化和量化。实际执行过程中sop核心是符合本企业并可执行，不流于形式。

- 什么是爬虫SOP

通过具体的方法，规则，习惯，管理数据采集的方式，有利于团队沟通、协作、交接。

## 数据采集工作的现状痛点

- 提需求：产品经理不会提数据采集需求，不能有效沟通
- 监控与告警：系统上线，监控、告警不到位，导致数据获取不稳定
- 数据质量：
	- 数据采集的质量，比如数据解析规则的容错性（鲁棒性），
	- 数据清洗的质量
	- 对业务的理解深度和数据表的设计
- 开发难度： 
  
	- APP抓包、逆向等
	
	- 不确定因素：在不开发的时候，不知道反爬是什么，破解、绕过难度多大，开发时间无法评估
- 法律风险：企业里，开发前需要经过法务审核
